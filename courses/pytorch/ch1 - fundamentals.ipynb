{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.12.1+cu102'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Tensors\n",
    "Their job is to represent data in a numerical way"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Creating tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(8)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(8)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dimensions\n",
    "scalar.ndim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get single Python integer value\n",
    "scalar.item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, tensor([1, 2, 3]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1, 2, 3])\n",
    "vector.ndim, vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`ndim` is the number of left (right) brackets '['"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)\n",
    "MATRIX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9]]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[[1,2,3], [4,5,6], [7,8,9]]]])\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)\n",
    "TENSOR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2783, 0.7273, 0.2696, 0.9542],\n        [0.9088, 0.0256, 0.5039, 0.9883],\n        [0.6169, 0.2908, 0.0283, 0.9927]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 4])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0., 0.],\n         [0., 0.]]),\n tensor([[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(size=(2, 2))\n",
    "ones_tensor = torch.ones(size=(3, 3))\n",
    "zeros_tensor, ones_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=1, end=10, step=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(MATRIX)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(zeros_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Tensor datatypes\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html#data-types\n",
    "\n",
    "some datatypes are specific for CPU and some are better for GPU\n",
    "\n",
    "lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(device(type='cpu'), torch.float32)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_32float = torch.tensor([3.0, 5.0, 7.0],\n",
    "                              dtype=None,  # default is torch.torch.float32\n",
    "                              device=None # use the default device\n",
    "                              )\n",
    "tensor_32float.device, tensor_32float.dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Common issues in PyTorch:\n",
    "* shapes of tensors don't match\n",
    "* different devices for tensors\n",
    "* require another type for tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.float16"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_16float = torch.tensor([1, 2, 1],\n",
    "                              dtype=torch.float16)\n",
    "tensor_16float.dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Tensor information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.float32, device(type='cpu'), torch.Size([1, 2, 3, 4, 5]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = torch.rand(size=(1, 2, 3, 4, 5))\n",
    "E.dtype, E.device, E.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Tensors manipulation\n",
    "All data (images, audio, text, etc) gets represented as tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 20],\n",
      "        [40, 50]])\n",
      "tensor([[1, 2],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2],\n",
    "                  [4, 5]])\n",
    "print(t * 10)\n",
    "# data in t has not changed\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[15, 30],\n        [60, 75]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(t, 15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2]) * tensor([4, 5]) = tensor([ 4, 10])\n"
     ]
    }
   ],
   "source": [
    "# pointwise\n",
    "print(f'{t[0]} * {t[1]} = {torch.multiply(t[0], t[1])}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2]) @ tensor([4, 5]) = 14\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication: 1st method which is faster\n",
    "print(f'{t[0]} @ {t[1].T} = {torch.matmul(t[0], t[1].T)}')\n",
    "#print(f'{t[0]} @ {t[1].T} = {torch.mm(t[0], t[1].T)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2]) @ tensor([4, 5]) = 14\n"
     ]
    }
   ],
   "source": [
    "# 2nd method for matrix multiplication\n",
    "print(f'{t[0]} @ {t[1].T} = {t[0] @ t[1].T}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 4.],\n        [2., 5.],\n        [3., 6.]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6]],\n",
    "                        dtype=torch.float32)\n",
    "# Techniques for transpose\n",
    "#tensor_A.T\n",
    "torch.transpose(tensor_A, dim0=0, dim1=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=3, out_features=1, bias=True)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(19)\n",
    "\n",
    "linear = torch.nn.Linear(in_features=3,\n",
    "                         out_features=1)\n",
    "linear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[1.3514],\n        [3.2511]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed-forward layer use matrix multiplication\n",
    "out = linear(tensor_A)\n",
    "print('output shape: ', out.shape)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = tensor(50.)\n",
      "min = tensor(1.)\n",
      "mean = tensor(16.5000)\n",
      "median = tensor(5.)\n",
      "sum = tensor(165.)\n"
     ]
    }
   ],
   "source": [
    "# aggregate functions\n",
    "M = torch.tensor([[1, 2, 3, 4, 5],\n",
    "                  [10, 20, 30, 40, 50]],\n",
    "                 dtype=torch.float32)\n",
    "print('max =', M.max())\n",
    "print('min =', M.min())\n",
    "print('mean =', M.mean())\n",
    "print('median =', M.median())\n",
    "print('sum =', M.sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = torch.return_types.max(\n",
      "values=tensor([10., 20., 30., 40., 50.]),\n",
      "indices=tensor([1, 1, 1, 1, 1]))\n",
      "min = torch.return_types.min(\n",
      "values=tensor([ 1., 10.]),\n",
      "indices=tensor([0, 0]))\n",
      "mean = tensor([ 3., 30.])\n",
      "median = torch.return_types.median(\n",
      "values=tensor([ 3., 30.]),\n",
      "indices=tensor([2, 2]))\n",
      "sum = tensor([11., 22., 33., 44., 55.])\n"
     ]
    }
   ],
   "source": [
    "print('max =', M.max(dim=0)) # max in each column\n",
    "print('min =', M.min(dim=1))  # min in each row\n",
    "print('mean =', M.mean(dim=1)) # mean for each row\n",
    "print('median =', M.median(dim=1)) # median for each row\n",
    "print('sum =', M.sum(dim=0)) # sum for each column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(9)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index of max value (!IN FLATTEN TENSOR)\n",
    "torch.argmax(M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(M, dim=1) # index of min in each row"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change tensor datatype\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.float32"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float32)\n",
    "tensor.dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Very important topic is how to reshape tensors**. PyTorch contain different methods for this task:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape tensor to shape if compatible\n",
    "tensor = tensor.reshape(shape=(3, 2))\n",
    "tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6]])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a view of the original tensor with another shape\n",
    "tmp = tensor.view((2, 3))\n",
    "tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1,  2],\n        [ 3,  4],\n        [15,  6]])"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify view of tensor equal to modify the original\n",
    "tmp[1, 1] = 15\n",
    "tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 3, 5],\n        [2, 4, 6]])"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenates a sequence of tensors along a new dimension\n",
    "t1 = torch.tensor([1, 2])\n",
    "t2 = torch.tensor([3, 4])\n",
    "t3 = torch.tensor([5, 6])\n",
    "torch.stack(tensors=[t1, t2, t3], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2]])\n",
      "shape is torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1, 2])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add dimension with value 1 at dim\n",
    "t1 = torch.unsqueeze(t1, dim=1)\n",
    "print(t1)\n",
    "print('shape is', t1.shape)\n",
    "\n",
    "# remove all the dimensions with value 1\n",
    "torch.squeeze(t1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 4, 5])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute the dimensions\n",
    "tensor_A = torch.rand(size=(4, 5, 3))\n",
    "tensor_A = tensor_A.permute(dims=(2,0,1))\n",
    "tensor_A.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. PyTorch + NumPy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type is torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4])"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array = np.array([1, 2, 3, 4])\n",
    "\n",
    "# from numpy to pytorch\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "print('type is', torch_tensor.dtype)\n",
    "torch_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3, 4])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back to numpy\n",
    "torch_tensor.numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Default type for numpy is float64, but pytorch often use float32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of elements in numpy array: float64\n",
      "type of elements in torch tensor: torch.float64\n",
      "type of elements in torch tensor AFTER TRANSFORM: torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1.0, 2., 3.1])\n",
    "print('type of elements in numpy array:', a.dtype)\n",
    "\n",
    "t = torch.from_numpy(a)\n",
    "print('type of elements in torch tensor:', t.dtype)\n",
    "\n",
    "t = torch.from_numpy(a).type(torch.float32)\n",
    "print('type of elements in torch tensor AFTER TRANSFORM:', t.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Reproducibility\n",
    "It can be useful when you want to perform repeatable experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2023, 0.4515],\n",
      "        [0.9240, 0.2862],\n",
      "        [0.0071, 0.6098],\n",
      "        [0.9307, 0.7573],\n",
      "        [0.7274, 0.2586]])\n",
      "tensor([[0.4472, 0.7946],\n",
      "        [0.6463, 0.3526],\n",
      "        [0.9688, 0.0623],\n",
      "        [0.5991, 0.6110],\n",
      "        [0.1700, 0.6772]])\n"
     ]
    }
   ],
   "source": [
    "rand_A = torch.rand(size=(5, 2))\n",
    "rand_B = torch.rand(size=(5, 2))\n",
    "print(rand_A)\n",
    "print(rand_B)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[False, False],\n        [False, False],\n        [False, False],\n        [False, False],\n        [False, False]])"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_A==rand_B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True],\n        [True, True],\n        [True, True],\n        [True, True],\n        [True, True]])"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "RANDOM_SEED = 19\n",
    "# set randomness\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_A = torch.rand(size=(5, 2))\n",
    "\n",
    "# if you want to be the same values in rand() function\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_B = torch.rand(size=(5, 2))\n",
    "rand_A==rand_B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. GPU and CPU\n",
    "Neural network require a lot of numerical operations. By default these operations are done on a CPU. Another common piece of hardware is a GPU, which is often much faster at performing the specific types of operations (like matrix multiplications) than CPUs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "best practice is to write **agnostic code** (could be run on Cpu OR GPU)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can put tensor on the device you set\n",
    "tensor = tensor.to(device)\n",
    "tensor.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "if tensor is on the GPU, it can't transform to NumPy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1,  2],\n       [ 3,  4],\n       [15,  6]])"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Practice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1\n",
    "Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on torch.Tensor and for torch.cuda."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2\n",
    "Create a random tensor with shape (7, 7)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.7633, 0.7557, 0.1536, 0.2635, 0.0415, 0.6492, 0.8437],\n        [0.8314, 0.8822, 0.0669, 0.4342, 0.3151, 0.2040, 0.1443],\n        [0.4630, 0.7861, 0.6378, 0.9377, 0.8173, 0.3743, 0.9132],\n        [0.0056, 0.3141, 0.5586, 0.8003, 0.3115, 0.8216, 0.8663],\n        [0.2617, 0.9900, 0.6988, 0.6661, 0.1711, 0.4917, 0.2130],\n        [0.4823, 0.5206, 0.7125, 0.6074, 0.1137, 0.4844, 0.4674],\n        [0.5858, 0.5613, 0.9119, 0.2263, 0.3823, 0.4847, 0.1190]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = torch.rand(size=(7,7))\n",
    "print(tens.shape)\n",
    "tens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3\n",
    "Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[2.4061],\n        [1.9980],\n        [2.4949],\n        [1.8935],\n        [1.9159],\n        [1.8621],\n        [1.6747]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_tens = torch.rand(size=(1, 7))\n",
    "multiplication = torch.mm(input=tens, mat2=another_tens.T)\n",
    "print(multiplication.shape)\n",
    "multiplication"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.4\n",
    "Set the random seed to 0 and do exercises 2 & 3 over again."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.8542],\n        [1.9611],\n        [2.2884],\n        [3.0481],\n        [1.7067],\n        [2.5290],\n        [1.7989]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed=0)\n",
    "tens = torch.rand(size=(7,7))\n",
    "another_tens = torch.rand(size=(1, 7))\n",
    "multiplication = torch.mm(input=tens, mat2=another_tens.T)\n",
    "multiplication"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.5\n",
    "Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(seed=1234)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.6\n",
    "Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0290, 0.4019, 0.2598],\n",
      "        [0.3666, 0.0583, 0.7006]])\n",
      "tensor([[0.0518, 0.4681, 0.6738],\n",
      "        [0.3315, 0.7837, 0.5631]])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "tens1 = torch.rand(size=(2, 3), device=device)\n",
    "tens2 = torch.rand(size=(2, 3), device=device)\n",
    "print(tens1)\n",
    "print(tens2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.7\n",
    "Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3647, 0.4709],\n        [0.5184, 0.5617]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tens1 @ tens2.T\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.8\n",
    "Find the maximum and minimum values of the output of 7."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = 0.5617256760597229, min = 0.3647301197052002\n"
     ]
    }
   ],
   "source": [
    "print('max = {}, min = {}'.format(out.max().item(), out.min().item()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.9\n",
    "Find the maximum and minimum index values of the output of 7."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of max = 3, index of min = 0\n"
     ]
    }
   ],
   "source": [
    "print('index of max = {}, index of min = {}'.format(out.argmax(), out.argmin()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.10\n",
    "Make a random tensor with shape (1, 1, 1, 7) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original tensor is torch.Size([1, 1, 1, 7]) and the tensor:\n",
      " tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071]]]])\n",
      "shape of new tensor is torch.Size([7]) and the tensor:\n",
      " tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed=7)\n",
    "random_tensor = torch.rand(size=(1, 1, 1, 7))\n",
    "print('shape of original tensor is {} and the tensor:\\n {}'.format(random_tensor.shape, random_tensor))\n",
    "\n",
    "other_tensor = random_tensor.squeeze()\n",
    "print('shape of new tensor is {} and the tensor:\\n {}'.format(other_tensor.shape, other_tensor))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
