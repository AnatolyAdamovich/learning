{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8e9d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84a0df",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "In this step we implement *gradient descent algorithm*. We will be working with simple linear regression model:  $f = w*x$, where $w_{true} = 2$.\n",
    "\n",
    "## Using only numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e48bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data consist of 4 different objects\n",
    "X_data = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "y_data = X_data * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ea619f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13893278])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial parameter\n",
    "w = np.random.rand(1)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179ce1f",
   "metadata": {},
   "source": [
    "define the functions that calculate **loss value** and **gradient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4e6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_pred, y_true):\n",
    "    # MSE\n",
    "    return ((y_pred - y_true)**2).mean()\n",
    "\n",
    "def gradient(x, y_pred, y_true):\n",
    "    #dMSE/dw = 2 * x * (y_pred - y_true) / 2\n",
    "    return np.dot(x, y_pred-y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e6359",
   "metadata": {},
   "source": [
    "define the function that calculate the output of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de55cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab342b",
   "metadata": {},
   "source": [
    "Now everything is ready for train our model and try to find the optimal value for `w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c2ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch № 0: loss = 25.976783868344008\n",
      "epoch № 1: loss = 12.728624095488563\n",
      "epoch № 2: loss = 6.237025806789397\n",
      "epoch № 3: loss = 3.056142645326805\n",
      "epoch № 4: loss = 1.4975098962101339\n",
      "epoch № 5: loss = 0.7337798491429652\n",
      "epoch № 6: loss = 0.3595521260800534\n",
      "epoch № 7: loss = 0.17618054177922593\n",
      "epoch № 8: loss = 0.08632846547182065\n",
      "epoch № 9: loss = 0.0423009480811921\n",
      "\n",
      "weights after training: [1.94742946]\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 10\n",
    "leaning_rate = 0.01\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "    output = model_predict(X_data)\n",
    "    # calculate the gradient\n",
    "    loss_value = loss(output, y_data)\n",
    "    grad = gradient(X_data, output, y_data)\n",
    "    \n",
    "    w = w - leaning_rate * grad\n",
    "    print(f'epoch № {epoch}: loss = {loss_value}')\n",
    "\n",
    "print()\n",
    "print('weights after training:', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a686f5",
   "metadata": {},
   "source": [
    "## Using backward and gradient from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e77e23f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6686], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our data\n",
    "X_data = torch.from_numpy(X_data)\n",
    "y_data = torch.from_numpy(y_data)\n",
    "\n",
    "# initial weights\n",
    "weights = torch.rand(1)*5\n",
    "weights.requires_grad_(True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7c7f939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 8.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8020123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(x):\n",
    "    return weights * x\n",
    "\n",
    "def loss_f(y_pred, y_true):\n",
    "    return ((y_pred - y_true)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5087b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch № 10: loss = 2.8652901649475098\n",
      "\n",
      "epoch № 20: loss = 0.1110573559999466\n",
      "\n",
      "epoch № 30: loss = 0.004304530099034309\n",
      "\n",
      "epoch № 40: loss = 0.0001668329641688615\n",
      "\n",
      "epoch № 50: loss = 6.467465027526487e-06\n",
      "\n",
      "epoch № 60: loss = 2.514570951461792e-07\n",
      "\n",
      "epoch № 70: loss = 9.707790127322369e-09\n",
      "\n",
      "epoch № 80: loss = 3.836930773104541e-10\n",
      "\n",
      "epoch № 90: loss = 1.5347723092418164e-11\n",
      "\n",
      "epoch № 100: loss = 3.595346242946107e-12\n",
      "\n",
      "weight = tensor([2.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "    # 1 step: forward pass\n",
    "    output = model_prediction(X_data)\n",
    "    \n",
    "    # 2 step: calculate loss function\n",
    "    loss_value = loss_f(output, y_data)\n",
    "    \n",
    "    # 3 step: calculate gradient\n",
    "    loss_value.backward()\n",
    "    \n",
    "    # 4 step: update our weights\n",
    "    with torch.no_grad():\n",
    "        weights -= learning_rate * weights.grad\n",
    "    \n",
    "    # 5 step: zero gradient\n",
    "    weights.grad.zero_()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch № {epoch+1}: loss = {loss_value}\\n')\n",
    "        \n",
    "print(f'weight = {weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf24ed",
   "metadata": {},
   "source": [
    "## Using optimizer, loss, backward and gradient from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75e0e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.4871], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(1)*15\n",
    "weights.requires_grad_(True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9ae8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(x):\n",
    "    return weights*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbadad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contstruct loss and optimizer\n",
    "optimizer = torch.optim.SGD([weights], lr=0.01)\n",
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d8796b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch №10: loss = 16.93170928955078\n",
      "\n",
      "epoch №20: loss = 0.656265914440155\n",
      "\n",
      "epoch №30: loss = 0.025436677038669586\n",
      "\n",
      "epoch №40: loss = 0.0009859043639153242\n",
      "\n",
      "epoch №50: loss = 3.820823985734023e-05\n",
      "\n",
      "epoch №60: loss = 1.481266735936515e-06\n",
      "\n",
      "epoch №70: loss = 5.710887762688799e-08\n",
      "\n",
      "epoch №80: loss = 2.143067945326038e-09\n",
      "\n",
      "epoch №90: loss = 8.355982572538778e-11\n",
      "\n",
      "epoch №100: loss = 3.595346242946107e-12\n",
      "\n",
      "weights = tensor([2.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epoches = 100\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "    output = model_prediction(X_data)\n",
    "    loss_value = loss(output, y_data)\n",
    "    loss_value.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch №{epoch+1}: loss = {loss_value}\\n')\n",
    "print(f'weights =', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d54d0",
   "metadata": {},
   "source": [
    "## Using only PyTorch packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45a39462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [4.],\n",
       "        [6.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preparing: each object is independent row\n",
    "X_data = X_data.reshape(-1, 1)\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5221335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5106]], requires_grad=True)\n",
      "epoch №1: loss = 16.637157440185547\n",
      "epoch №2: loss = 1.0398225784301758\n",
      "epoch №3: loss = 0.06498882919549942\n",
      "epoch №4: loss = 0.004061833024024963\n",
      "epoch №5: loss = 0.0002538588596507907\n",
      "epoch №6: loss = 1.5866437024669722e-05\n",
      "epoch №7: loss = 9.916036560753128e-07\n",
      "epoch №8: loss = 6.191835666413681e-08\n",
      "epoch №9: loss = 3.8395029378079926e-09\n",
      "epoch №10: loss = 2.455635694786906e-10\n",
      "model prediction for x=5:  9.999992370605469\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n",
    "print(next(model.parameters()))\n",
    "\n",
    "# construct loss and optimizer\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.05)\n",
    "\n",
    "# training loop\n",
    "n_epoches = 10\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "    # 1: forward pass\n",
    "    output = model(X_data)\n",
    "    # 2: calculate loss function\n",
    "    loss_value = loss_function(output, y_data)\n",
    "    \n",
    "    # 3: calculate the gradient\n",
    "    loss_value.backward()\n",
    "    \n",
    "    # 4: update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 5 zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(f'epoch №{epoch+1}: loss = {loss_value}')\n",
    "        \n",
    "print(f'model prediction for x=5: ', model(torch.tensor([5.])).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
